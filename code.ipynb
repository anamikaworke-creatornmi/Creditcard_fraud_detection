{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59eaabb1-5e5d-45bc-9b88-dbd15fa0877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hehe\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 1. IMPORT LIBRARIES\n",
    "# =========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e9128a-3159-4521-9691-36ccaba019a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 2. LOAD DATASET (Kaggle 2023 dataset)\n",
    "# =========================================\n",
    "df = pd.read_csv(\"creditcard_2023.csv\")   # change path accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df2fa1a-76f0-43b9-9bc4-4c7db88418f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% fraud subset distribution:\n",
      " Class\n",
      "0    239976\n",
      "1      2424\n",
      "Name: count, dtype: int64\n",
      "Dataset 1 distribution:\n",
      " Class\n",
      "0    40000\n",
      "1      400\n",
      "Name: count, dtype: int64\n",
      "Dataset 2 distribution:\n",
      " Class\n",
      "0    80000\n",
      "1      800\n",
      "Name: count, dtype: int64\n",
      "Dataset 3 distribution:\n",
      " Class\n",
      "0    120000\n",
      "1      1200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 2. CREATE 1% FRAUD SUBSET (242,400 records)\n",
    "# =========================================\n",
    "# Separate fraud and non-fraud\n",
    "fraud = df[df['Class'] == 1]\n",
    "non_fraud = df[df['Class'] == 0]\n",
    "\n",
    "# Number of records for 1% fraud subset\n",
    "subset_size = 242400\n",
    "fraud_count = int(subset_size * 0.01)   # 1% fraud\n",
    "non_fraud_count = subset_size - fraud_count  # remaining non-fraud\n",
    "\n",
    "# Randomly sample to create subset\n",
    "fraud_subset = fraud.sample(fraud_count, random_state=42)\n",
    "non_fraud_subset = non_fraud.sample(non_fraud_count, random_state=42)\n",
    "\n",
    "subset_1pct = pd.concat([fraud_subset, non_fraud_subset]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"1% fraud subset distribution:\\n\", subset_1pct['Class'].value_counts())\n",
    "\n",
    "# =========================================\n",
    "# 3. CREATE THREE IMBALANCED SUBSETS\n",
    "# =========================================\n",
    "# Dataset 1: 40,400 records (40,000 non-fraudulent, 400 fraudulent)\n",
    "subset1 = pd.concat([\n",
    "    non_fraud_subset.sample(40000, random_state=42),\n",
    "    fraud_subset.sample(400, random_state=42)\n",
    "]).sample(frac=1, random_state=42)\n",
    "\n",
    "# Dataset 2: 80,800 records (80,000 non-fraudulent, 800 fraudulent)\n",
    "subset2 = pd.concat([\n",
    "    non_fraud_subset.sample(80000, random_state=42),\n",
    "    fraud_subset.sample(800, random_state=42)\n",
    "]).sample(frac=1, random_state=42)\n",
    "\n",
    "# Dataset 3: 121,200 records (120,000 non-fraudulent, 1,200 fraudulent)\n",
    "subset3 = pd.concat([\n",
    "    non_fraud_subset.sample(120000, random_state=42),\n",
    "    fraud_subset.sample(1200, random_state=42)\n",
    "]).sample(frac=1, random_state=42)\n",
    "\n",
    "# Quick sanity check\n",
    "print(\"Dataset 1 distribution:\\n\", subset1['Class'].value_counts())\n",
    "print(\"Dataset 2 distribution:\\n\", subset2['Class'].value_counts())\n",
    "print(\"Dataset 3 distribution:\\n\", subset3['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec95962-db8b-4a28-bbf9-cc87bd49e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 3. CREATE THREE IMBALANCED SUBSETS (1% fraud)\n",
    "# =========================================\n",
    "fraud = df[df['Class'] == 1]\n",
    "non_fraud = df[df['Class'] == 0]\n",
    "\n",
    "subset1 = pd.concat([\n",
    "    non_fraud.iloc[:40000],\n",
    "    fraud.iloc[:400]\n",
    "]).sample(frac=1, random_state=42)\n",
    "\n",
    "subset2 = pd.concat([\n",
    "    non_fraud.iloc[:80000],\n",
    "    fraud.iloc[:800]\n",
    "]).sample(frac=1, random_state=42)\n",
    "\n",
    "subset3 = pd.concat([\n",
    "    non_fraud.iloc[:120000],\n",
    "    fraud.iloc[:1200]\n",
    "]).sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ceb4dc-7485-434f-a448-cd2150e8e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 4. PREPROCESSING FUNCTION\n",
    "# =========================================\n",
    "def preprocess_data(df_subset):\n",
    "    \n",
    "    # Remove missing values\n",
    "    df_clean = df_subset.dropna()\n",
    "    \n",
    "    X = df_clean.drop(\"Class\", axis=1)\n",
    "    y = df_clean[\"Class\"]\n",
    "    \n",
    "    # Standard Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_pca = scaler.fit_transform(X)\n",
    "    \n",
    "    # PCA (28 components as in dataset)\n",
    "    # pca = PCA(n_components=28)\n",
    "    # X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    return X_pca, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29035732-40f3-4960-bfda-b2fb3becfeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 5. DBSCAN AUGMENTATION (ITERATIVE)\n",
    "# =========================================\n",
    "def dbscan_augmentation(X, eps=2, min_samples=4, iterations=2):\n",
    "    \n",
    "    X_aug = X.copy()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = db.fit_predict(X_aug)\n",
    "        \n",
    "        labels = labels.reshape(-1, 1)\n",
    "        X_aug = np.hstack((X_aug, labels))\n",
    "    \n",
    "    return X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dacbd26-6670-4563-9794-5c2c5e5c8935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Subset 1 (40,400) ==========\n",
      "\n",
      "               Accuracy  Precision_0  Recall_0      F1_0  Precision_1  \\\n",
      "Random Forest  0.999134     0.999500  0.999625  0.999563     0.962025   \n",
      "KNN            0.999752     1.000000  0.999750  0.999875     0.975610   \n",
      "SVM            0.998762     0.999001  0.999750  0.999375     0.972973   \n",
      "Voting OR      0.999505     1.000000  0.999500  0.999750     0.952381   \n",
      "\n",
      "               Recall_1      F1_1  \n",
      "Random Forest      0.95  0.955975  \n",
      "KNN                1.00  0.987654  \n",
      "SVM                0.90  0.935065  \n",
      "Voting OR          1.00  0.975610  \n",
      "\n",
      "Confusion Matrix for Voting OR:\n",
      "[[7996    4]\n",
      " [   0   80]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_and_evaluate(df_subset, name=\"Dataset\"):\n",
    "    \n",
    "    print(f\"\\n========== {name} ==========\\n\")\n",
    "    \n",
    "    # Preprocess\n",
    "    X, y = preprocess_data(df_subset)\n",
    "    \n",
    "    # Augmentation\n",
    "    X_aug = dbscan_augmentation(X, eps=2, min_samples=4, iterations=2)\n",
    "    \n",
    "    # 80-20 Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_aug, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # ==================================\n",
    "    # Models (Exact paper parameters)\n",
    "    # ==================================\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=3, max_depth=None, random_state=42)\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    svm = SVC(kernel='rbf', C=1.0)\n",
    "    \n",
    "    # Train\n",
    "    rf.fit(X_train, y_train)\n",
    "    knn.fit(X_train, y_train)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    \n",
    "    # ==================================\n",
    "    # Disjunctive (OR) Voting\n",
    "    # Fraud if ANY classifier predicts fraud\n",
    "    # ==================================\n",
    "    voting_pred = np.array([\n",
    "        1 if (rf_pred[i] == 1 or knn_pred[i] == 1 or svm_pred[i] == 1) else 0\n",
    "        for i in range(len(y_test))\n",
    "    ])\n",
    "    \n",
    "    # ==================================\n",
    "    # Evaluate all models + voting\n",
    "    # ==================================\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    \n",
    "    models_preds = {\n",
    "        'Random Forest': rf_pred,\n",
    "        'KNN': knn_pred,\n",
    "        'SVM': svm_pred,\n",
    "        'Voting OR': voting_pred\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, y_pred in models_preds.items():\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        results[model_name] = {\n",
    "            'Accuracy': acc,\n",
    "            'Precision_0': report['0']['precision'],\n",
    "            'Recall_0': report['0']['recall'],\n",
    "            'F1_0': report['0']['f1-score'],\n",
    "            'Precision_1': report['1']['precision'],\n",
    "            'Recall_1': report['1']['recall'],\n",
    "            'F1_1': report['1']['f1-score']\n",
    "        }\n",
    "    \n",
    "    # Display results table\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    print(df_results)\n",
    "    \n",
    "    # Optional: show confusion matrix for the voting classifier\n",
    "    print(\"\\nConfusion Matrix for Voting OR:\")\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, voting_pred))\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# =========================================\n",
    "# 7. RUN EXPERIMENTS (Case Study 2)\n",
    "# =========================================\n",
    "df_results1 = train_and_evaluate(subset1, \"Subset 1 (40,400)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e670dc87-d03a-4503-8eba-b47731775abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Subset 2  ==========\n",
      "\n",
      "               Accuracy  Precision_0  Recall_0      F1_0  Precision_1  \\\n",
      "Random Forest  0.999505     0.999500  1.000000  0.999750     1.000000   \n",
      "KNN            0.998948     0.999250  0.999687  0.999469     0.967320   \n",
      "SVM            0.997153     0.997381  0.999750  0.998564     0.967213   \n",
      "Voting OR      0.999381     0.999687  0.999687  0.999687     0.968750   \n",
      "\n",
      "               Recall_1      F1_1  \n",
      "Random Forest   0.95000  0.974359  \n",
      "KNN             0.92500  0.945687  \n",
      "SVM             0.73750  0.836879  \n",
      "Voting OR       0.96875  0.968750  \n",
      "\n",
      "Confusion Matrix for Voting OR:\n",
      "[[15995     5]\n",
      " [    5   155]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.999505</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.998948</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>0.967320</td>\n",
       "      <td>0.92500</td>\n",
       "      <td>0.945687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.997381</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.836879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting OR</th>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Precision_0  Recall_0      F1_0  Precision_1  \\\n",
       "Random Forest  0.999505     0.999500  1.000000  0.999750     1.000000   \n",
       "KNN            0.998948     0.999250  0.999687  0.999469     0.967320   \n",
       "SVM            0.997153     0.997381  0.999750  0.998564     0.967213   \n",
       "Voting OR      0.999381     0.999687  0.999687  0.999687     0.968750   \n",
       "\n",
       "               Recall_1      F1_1  \n",
       "Random Forest   0.95000  0.974359  \n",
       "KNN             0.92500  0.945687  \n",
       "SVM             0.73750  0.836879  \n",
       "Voting OR       0.96875  0.968750  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate(subset2, \"Subset 2 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb23329-1638-48b0-9be9-252629bfed6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Subset 3  ==========\n",
      "\n",
      "               Accuracy  Precision_0  Recall_0      F1_0  Precision_1  \\\n",
      "Random Forest  0.999917     0.999917  1.000000  0.999958     1.000000   \n",
      "KNN            0.999464     0.999583  0.999875  0.999729     0.987124   \n",
      "SVM            0.996700     0.996802  0.999875  0.998336     0.981928   \n",
      "Voting OR      0.999752     0.999958  0.999792  0.999875     0.979508   \n",
      "\n",
      "               Recall_1      F1_1  \n",
      "Random Forest  0.991667  0.995816  \n",
      "KNN            0.958333  0.972516  \n",
      "SVM            0.679167  0.802956  \n",
      "Voting OR      0.995833  0.987603  \n",
      "\n",
      "Confusion Matrix for Voting OR:\n",
      "[[23995     5]\n",
      " [    1   239]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.999917</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.995816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.999464</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.972516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.996700</td>\n",
       "      <td>0.996802</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.998336</td>\n",
       "      <td>0.981928</td>\n",
       "      <td>0.679167</td>\n",
       "      <td>0.802956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting OR</th>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.987603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Precision_0  Recall_0      F1_0  Precision_1  \\\n",
       "Random Forest  0.999917     0.999917  1.000000  0.999958     1.000000   \n",
       "KNN            0.999464     0.999583  0.999875  0.999729     0.987124   \n",
       "SVM            0.996700     0.996802  0.999875  0.998336     0.981928   \n",
       "Voting OR      0.999752     0.999958  0.999792  0.999875     0.979508   \n",
       "\n",
       "               Recall_1      F1_1  \n",
       "Random Forest  0.991667  0.995816  \n",
       "KNN            0.958333  0.972516  \n",
       "SVM            0.679167  0.802956  \n",
       "Voting OR      0.995833  0.987603  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate(subset3, \"Subset 3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b148575-7f7c-4201-be6d-7e4b232b84bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
