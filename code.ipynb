{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59eaabb1-5e5d-45bc-9b88-dbd15fa0877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e9128a-3159-4521-9691-36ccaba019a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard_2023.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df2fa1a-76f0-43b9-9bc4-4c7db88418f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% fraud subset distribution:\n",
      " Class\n",
      "0    239976\n",
      "1      2424\n",
      "Name: count, dtype: int64\n",
      "Dataset 1 distribution:\n",
      " Class\n",
      "0    40000\n",
      "1      400\n",
      "Name: count, dtype: int64\n",
      "Dataset 2 distribution:\n",
      " Class\n",
      "0    80000\n",
      "1      800\n",
      "Name: count, dtype: int64\n",
      "Dataset 3 distribution:\n",
      " Class\n",
      "0    120000\n",
      "1      1200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fraud = df[df['Class'] == 1]\n",
    "non_fraud = df[df['Class'] == 0]\n",
    "\n",
    "# =========================================\n",
    "# 1% FRAUD DATASET (242,400 total)\n",
    "# =========================================\n",
    "subset_size = 242400\n",
    "fraud_count = int(subset_size * 0.01)   # 1%\n",
    "non_fraud_count = subset_size - fraud_count\n",
    "\n",
    "subset_1pct = pd.concat([\n",
    "    fraud.sample(fraud_count, random_state=42),\n",
    "    non_fraud.sample(non_fraud_count, random_state=42)\n",
    "]).sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"1% fraud subset distribution:\\n\", subset_1pct['Class'].value_counts())\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# THREE SEPARATE IMBALANCED DATASETS\n",
    "# =========================================\n",
    "\n",
    "def create_dataset(n_non_fraud, n_fraud, seed=42):\n",
    "    return pd.concat([\n",
    "        non_fraud.sample(n_non_fraud, random_state=seed),\n",
    "        fraud.sample(n_fraud, random_state=seed)\n",
    "    ]).sample(frac=1, random_state=seed)\n",
    "\n",
    "subset1 = create_dataset(40000, 400)\n",
    "subset2 = create_dataset(80000, 800)\n",
    "subset3 = create_dataset(120000, 1200)\n",
    "\n",
    "print(\"Dataset 1 distribution:\\n\", subset1['Class'].value_counts())\n",
    "print(\"Dataset 2 distribution:\\n\", subset2['Class'].value_counts())\n",
    "print(\"Dataset 3 distribution:\\n\", subset3['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ceb4dc-7485-434f-a448-cd2150e8e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 4. PREPROCESSING FUNCTION\n",
    "# =========================================\n",
    "def preprocess_data(df_subset):\n",
    "    \n",
    "    # Remove missing values\n",
    "    df_clean = df_subset.dropna()\n",
    "    \n",
    "    X = df_clean.drop(\"Class\", axis=1)\n",
    "    y = df_clean[\"Class\"]\n",
    "    \n",
    "    # Standard Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_pca = scaler.fit_transform(X)\n",
    "    \n",
    "    # PCA (28 components as in dataset)\n",
    "    # pca = PCA(n_components=28)\n",
    "    # X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    return X_pca, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29035732-40f3-4960-bfda-b2fb3becfeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 5. DBSCAN AUGMENTATION (ITERATIVE)\n",
    "# =========================================\n",
    "def dbscan_augmentation(X, eps=2, min_samples=4, iterations=2):\n",
    "    \n",
    "    X_aug = X.copy()\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = db.fit_predict(X_aug)\n",
    "        \n",
    "        labels = labels.reshape(-1, 1)\n",
    "        X_aug = np.hstack((X_aug, labels))\n",
    "    \n",
    "    return X_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dacbd26-6670-4563-9794-5c2c5e5c8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate(df_subset, name=\"Dataset\"):\n",
    "    \n",
    "    print(f\"\\n========== {name} ==========\\n\")\n",
    "    \n",
    "    # Preprocess\n",
    "    X, y = preprocess_data(df_subset)\n",
    "    \n",
    "    # Augmentation\n",
    "    X_aug = dbscan_augmentation(X, eps=2, min_samples=4, iterations=2)\n",
    "    \n",
    "    # 80-20 Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_aug, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # ==================================\n",
    "    # Models (Exact paper parameters)\n",
    "    # ==================================\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=3, max_depth=None, random_state=42)\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    svm = SVC(kernel='rbf', C=1.0)\n",
    "    \n",
    "    # Train\n",
    "    rf.fit(X_train, y_train)\n",
    "    knn.fit(X_train, y_train)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    \n",
    "    # ==================================\n",
    "    # Disjunctive (OR) Voting\n",
    "    # Fraud if ANY classifier predicts fraud\n",
    "    # ==================================\n",
    "    voting_pred = np.array([\n",
    "        1 if (rf_pred[i] == 1 or knn_pred[i] == 1 or svm_pred[i] == 1) else 0\n",
    "        for i in range(len(y_test))\n",
    "    ])\n",
    "    \n",
    "    # ==================================\n",
    "    # Evaluate all models + voting\n",
    "    # ==================================\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    \n",
    "    models_preds = {\n",
    "        'Random Forest': rf_pred,\n",
    "        'KNN': knn_pred,\n",
    "        'SVM': svm_pred,\n",
    "        'Voting OR': voting_pred\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, y_pred in models_preds.items():\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        results[model_name] = {\n",
    "            'Accuracy': acc,\n",
    "            'Precision_0': report['0']['precision'],\n",
    "            'Recall_0': report['0']['recall'],\n",
    "            'F1_0': report['0']['f1-score'],\n",
    "            'Precision_1': report['1']['precision'],\n",
    "            'Recall_1': report['1']['recall'],\n",
    "            'F1_1': report['1']['f1-score']\n",
    "        }\n",
    "    \n",
    "    # Display results table\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    print(df_results)\n",
    "    \n",
    "    # Optional: show confusion matrix for the voting classifier\n",
    "    print(\"\\nConfusion Matrix for Voting OR:\")\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, voting_pred))\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# =========================================\n",
    "# 7. RUN EXPERIMENTS (Case Study 2)\n",
    "# =========================================\n",
    "df_results1 = train_and_evaluate(subset1, \"Subset 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e670dc87-d03a-4503-8eba-b47731775abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Subset 2  ==========\n",
      "\n",
      "               Accuracy  Precision_0  Recall_0      F1_0  Precision_1  \\\n",
      "Random Forest  0.999505     0.999500  1.000000  0.999750     1.000000   \n",
      "KNN            0.998948     0.999250  0.999687  0.999469     0.967320   \n",
      "SVM            0.997153     0.997381  0.999750  0.998564     0.967213   \n",
      "Voting OR      0.999381     0.999687  0.999687  0.999687     0.968750   \n",
      "\n",
      "               Recall_1      F1_1  \n",
      "Random Forest   0.95000  0.974359  \n",
      "KNN             0.92500  0.945687  \n",
      "SVM             0.73750  0.836879  \n",
      "Voting OR       0.96875  0.968750  \n",
      "\n",
      "Confusion Matrix for Voting OR:\n",
      "[[15995     5]\n",
      " [    5   155]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>F1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.999505</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.998948</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>0.967320</td>\n",
       "      <td>0.92500</td>\n",
       "      <td>0.945687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.997381</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.998564</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.836879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting OR</th>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy  Precision_0  Recall_0      F1_0  Precision_1  \\\n",
       "Random Forest  0.999505     0.999500  1.000000  0.999750     1.000000   \n",
       "KNN            0.998948     0.999250  0.999687  0.999469     0.967320   \n",
       "SVM            0.997153     0.997381  0.999750  0.998564     0.967213   \n",
       "Voting OR      0.999381     0.999687  0.999687  0.999687     0.968750   \n",
       "\n",
       "               Recall_1      F1_1  \n",
       "Random Forest   0.95000  0.974359  \n",
       "KNN             0.92500  0.945687  \n",
       "SVM             0.73750  0.836879  \n",
       "Voting OR       0.96875  0.968750  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate(subset2, \"Subset 2 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb23329-1638-48b0-9be9-252629bfed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(subset3, \"Subset 3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b148575-7f7c-4201-be6d-7e4b232b84bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
